{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"nested-shaper \u00b6 Getting Started \u00b6 The programmatic usage guide is available in the repository . nested-shaper is a flexible input shaping library utilizing nested simple moving averages (SMA). nested-shaper is designed to smooth trajectories by transforming lower-order polynomial trajectories into higher-order polynomial trajectories. By configuring the amplitude of the SMA , users can limit the maximum value of the derivatives of the trajectory. While SMAs are commonly used for noise reduction in signal processing, nested-shaper is not intended for this purpose. Instead, nested-shaper processes trajectory samples at specific intervals, outputting a point on a higher-order trajectory along with the derivative values of the trajectory. nested-shaper does not generate trajectories under physical constraints. It smooths pre-defined trajectories and can be used in conjunction with trajectory generation libraries such as ruckig nested-shaper is implemented in C++14, is header-only, and does not require the C++ standard library, making it suitable for minimal size embedded systems. When Should I Use It? \u00b6 In most cases, jerk (the fourth derivative of position) suffices for precise model-based control of systems. However, some systems may require: Snap (the fifth derivative of position) Crackle (the sixth derivative of position) Pop (the seventh derivative of position) or higher-order derivatives. Generating a trajectory with crackle continuity is computationally expensive. Here, nested-shaper provides a solution. Assume an optimal jerk-limited trajectory is created. During runtime, nested-shaper outputs a shaped trajectory with limited snap, crackle, pop, or higher derivatives. How It Works \u00b6 The Theory section explains the background of SMA and its role in creating higher-order trajectories. It briefly covers concepts such as convolution, Laplace transforms, and inverse transforms. Advanced Guide \u00b6 While nested-shaper operates by averaging datasets, averaging is not always straightforward. For instance, averaging 3D rotations (and even 1D rotations) is more complex than averaging 1D scalar variables. The Advanced Guide explains how to customize averaging metrics based on different datasets. License \u00b6 nested-shaper is free to use and modify under the terms of the permissive BSD 3-clause license","title":"Home"},{"location":"#nested-shaper","text":"","title":"nested-shaper"},{"location":"#getting-started","text":"The programmatic usage guide is available in the repository . nested-shaper is a flexible input shaping library utilizing nested simple moving averages (SMA). nested-shaper is designed to smooth trajectories by transforming lower-order polynomial trajectories into higher-order polynomial trajectories. By configuring the amplitude of the SMA , users can limit the maximum value of the derivatives of the trajectory. While SMAs are commonly used for noise reduction in signal processing, nested-shaper is not intended for this purpose. Instead, nested-shaper processes trajectory samples at specific intervals, outputting a point on a higher-order trajectory along with the derivative values of the trajectory. nested-shaper does not generate trajectories under physical constraints. It smooths pre-defined trajectories and can be used in conjunction with trajectory generation libraries such as ruckig nested-shaper is implemented in C++14, is header-only, and does not require the C++ standard library, making it suitable for minimal size embedded systems.","title":"Getting Started"},{"location":"#when-should-i-use-it","text":"In most cases, jerk (the fourth derivative of position) suffices for precise model-based control of systems. However, some systems may require: Snap (the fifth derivative of position) Crackle (the sixth derivative of position) Pop (the seventh derivative of position) or higher-order derivatives. Generating a trajectory with crackle continuity is computationally expensive. Here, nested-shaper provides a solution. Assume an optimal jerk-limited trajectory is created. During runtime, nested-shaper outputs a shaped trajectory with limited snap, crackle, pop, or higher derivatives.","title":"When Should I Use It?"},{"location":"#how-it-works","text":"The Theory section explains the background of SMA and its role in creating higher-order trajectories. It briefly covers concepts such as convolution, Laplace transforms, and inverse transforms.","title":"How It Works"},{"location":"#advanced-guide","text":"While nested-shaper operates by averaging datasets, averaging is not always straightforward. For instance, averaging 3D rotations (and even 1D rotations) is more complex than averaging 1D scalar variables. The Advanced Guide explains how to customize averaging metrics based on different datasets.","title":"Advanced Guide"},{"location":"#license","text":"nested-shaper is free to use and modify under the terms of the permissive BSD 3-clause license","title":"License"},{"location":"advanced_guide/","text":"Advanced Guide of nested-shaper \u00b6 nested-shaper supports average metrics on euclidean space and lie algebra space. However, if you want to apply other metrics on your custom algebra space, advanced guide explains how to do that. Also you can apply your array / vector types as input / output. Support custom data type / average metrics / algebra space \u00b6 All default class aliases came from ShaperMetrics. template < typename Type , size_t Dimension , size_t DerivativeOrder , size_t ... Extents > using NestedShaperEuclideanRecursiveArray = ShaperMetrics < array < Type , Dimension > , EuclideanDerivativeMetricsArray < Type , Dimension , DerivativeOrder > , DerivativeOrder , EuclideanMeanRecursiveMetricsArray < Type , Dimension > , Extents ... > ; NestedShaperEuclideanRecursiveArray class is template with array<Type, Dimension> as input data type, EuclideanDerivativeMetricsArray<Type, Dimension, DerivativeOrder> as metrics for calculating derivatives, DerivativeOrder as queue size of last position data for calculating derivatives, EuclideanMeanRecursiveMetricsArray<Type, Dimension> as metrics for calculating averages of each filter. Extents... as queue extents in order to store size of moving average filter. Step 1. \u00b6 Decide your data type. Let we assume input data type is 3D, std::array<double, 3> . Step 2. \u00b6 Implement a functor, about How to calculate derivatives from queue. Euclidean 1D implementation [nested-shaper/metrics/euclidean_derivative_metrics.hpp] template < size_t DerivativeOrder > struct MyDerivativeMetrics { MyReturnType operator () ( QueueConstIterator < std :: array < double , 3 >> forwardIterator , QueueConstIterator < std :: array < double , 3 >> backwardIterator , const Type & dt ) { // MyReturnType will be result type of convolute method. // By iterators, you can access last queue data of nested moving average filters. // You must use forwardIterator with operator++. or forwardIterator + N // You must use backwardIterator with operator--. or forwardIterator - N } }; Step 3. \u00b6 Implement a functor, about How to calculate average of queue. Euclidean 1D implementation [nested-shaper/metrics/euclidean_mean_recursive_metrics.hpp] struct MyAverageMetrics { std :: array < double , 3 > operator ()( const std :: array < double , 3 >& mean , const std :: array < double , 3 >& popped , const std :: array < double , 3 >& pushed , QueueConstIterator < std :: array < double , 3 >> forwardIterator , QueueConstIterator < std :: array < double , 3 >> backwardIterator ){ // You can average data, by recursively using previous mean, pushed data and popped data. // Or you can average data by cumulative using iterator. } }; Step 4. \u00b6 Adapt to ShaperMetrics. template < size_t DerivativeOrder , size_t ... Extents > using MyNestedShaper = ShaperMetrics < std :: array < double , 3 > , MyDerivativeMetrics < DerivativeOrder > , DerivativeOrder , MyAverageMetrics , Extents ... > ;","title":"Advanced Guide"},{"location":"advanced_guide/#advanced-guide-of-nested-shaper","text":"nested-shaper supports average metrics on euclidean space and lie algebra space. However, if you want to apply other metrics on your custom algebra space, advanced guide explains how to do that. Also you can apply your array / vector types as input / output.","title":"Advanced Guide of nested-shaper"},{"location":"advanced_guide/#support-custom-data-type-average-metrics-algebra-space","text":"All default class aliases came from ShaperMetrics. template < typename Type , size_t Dimension , size_t DerivativeOrder , size_t ... Extents > using NestedShaperEuclideanRecursiveArray = ShaperMetrics < array < Type , Dimension > , EuclideanDerivativeMetricsArray < Type , Dimension , DerivativeOrder > , DerivativeOrder , EuclideanMeanRecursiveMetricsArray < Type , Dimension > , Extents ... > ; NestedShaperEuclideanRecursiveArray class is template with array<Type, Dimension> as input data type, EuclideanDerivativeMetricsArray<Type, Dimension, DerivativeOrder> as metrics for calculating derivatives, DerivativeOrder as queue size of last position data for calculating derivatives, EuclideanMeanRecursiveMetricsArray<Type, Dimension> as metrics for calculating averages of each filter. Extents... as queue extents in order to store size of moving average filter.","title":"Support custom data type / average metrics / algebra space"},{"location":"advanced_guide/#step-1","text":"Decide your data type. Let we assume input data type is 3D, std::array<double, 3> .","title":"Step 1."},{"location":"advanced_guide/#step-2","text":"Implement a functor, about How to calculate derivatives from queue. Euclidean 1D implementation [nested-shaper/metrics/euclidean_derivative_metrics.hpp] template < size_t DerivativeOrder > struct MyDerivativeMetrics { MyReturnType operator () ( QueueConstIterator < std :: array < double , 3 >> forwardIterator , QueueConstIterator < std :: array < double , 3 >> backwardIterator , const Type & dt ) { // MyReturnType will be result type of convolute method. // By iterators, you can access last queue data of nested moving average filters. // You must use forwardIterator with operator++. or forwardIterator + N // You must use backwardIterator with operator--. or forwardIterator - N } };","title":"Step 2."},{"location":"advanced_guide/#step-3","text":"Implement a functor, about How to calculate average of queue. Euclidean 1D implementation [nested-shaper/metrics/euclidean_mean_recursive_metrics.hpp] struct MyAverageMetrics { std :: array < double , 3 > operator ()( const std :: array < double , 3 >& mean , const std :: array < double , 3 >& popped , const std :: array < double , 3 >& pushed , QueueConstIterator < std :: array < double , 3 >> forwardIterator , QueueConstIterator < std :: array < double , 3 >> backwardIterator ){ // You can average data, by recursively using previous mean, pushed data and popped data. // Or you can average data by cumulative using iterator. } };","title":"Step 3."},{"location":"advanced_guide/#step-4","text":"Adapt to ShaperMetrics. template < size_t DerivativeOrder , size_t ... Extents > using MyNestedShaper = ShaperMetrics < std :: array < double , 3 > , MyDerivativeMetrics < DerivativeOrder > , DerivativeOrder , MyAverageMetrics , Extents ... > ;","title":"Step 4."},{"location":"theory/","text":"Theory inside nested-shaper \u00b6 Definitions of Convolution \u00b6 \\[ h(t) = \\int_{-\\infty}^{\\infty}f(x)g(t-x)dx=f(t)*g(t) \\tag{continuous domain} \\] \\[ h[n] = (f*g)[n]=\\sum_{i=0}^{K-1}f[k] \\cdot g[n-k] \\tag{discrete domain} \\] The Convolution Theorem \u00b6 \\[ h = f * g \\iff H[m] = F[m] \\cdot G[m] \\iff H(s)= F(s)G(s) \\] Step and SMA function in frequency domain \u00b6 Step function, defined by \\[ u(t)=\\begin{cases} 0 & \\text{if } t < 0 \\\\ A & \\text{if } t \\geq 0 \\\\ \\end{cases} \\to U(s)=\\mathcal{L}\\{u(t)\\}=\\frac{A}{s} \\tag{1} \\] SMA function, defined by \\[ \\text{SMA}_k(t)=\\frac{1}{T_k}(H(t)-H(t-T_k)) \\to \\text{SMA}_k(s) = \\mathcal{L}\\{SMA_k(t)\\} = \\frac{1}{T_k}(\\frac{1-e^{T_ks}}{s}) \\tag{2} \\] Heaviside unit step, defined by \\[ H(t)=\\begin{cases} 1 & \\text{if } t \\geq 0 \\\\ 0 & \\text{if } t < 0 \\\\ \\end{cases} \\] Laplace transforms used in this theory \u00b6 \\[ \\mathcal{L}\\{t^{n}\\}=\\frac{n!}{s^{n+1}} \\tag{3} \\] \\[ \\mathcal{L}\\{H(t-a)\\}=\\frac{e^{-as}}{s}\\ (a \\geq 0) \\tag{4} \\] \\[ \\mathcal{L}\\{f(t-a)H(t-a)\\}=e^{-as}\\mathcal{L}\\{f(t)\\} \\tag{5} \\] Step function with nested SMA. \u00b6 Based on the convolution theorem, we apply nested SMAs(total n) on step function. $$ R(s)=U(s)\\text{SMA}_1(s)\\text{SMA}_2(s)\\cdots\\text{SMA}_n(s) $$ \\[ =\\frac{A}{s^{n+1}}\\frac{1}{T_1T_2\\cdots T_n}(1-e^{T_1s})(1-e^{T_2s})\\cdots (1-e^{T_ns})=\\frac{A}{n!}\\frac{n!}{s^{n+1}}\\frac{1}{\\prod^{n}_{k=1}T_{k}}\\prod^{n}_{k=1}(1-e^{T_ks}) \\] \\[ =\\frac{A}{n!}\\frac{n!}{s^{n+1}}\\frac{1}{\\prod^{n}_{k=1}T_{k}}\\sum^{n}_{k=0}(-1)^k\\sum_{\\stackrel{I\\subseteq\\{1,2,\\cdots,n\\}}{|I|=k}}e^{-s\\sum_{i\\in I}T_i} \\tag{6} \\] If SMAs have same amplitude, \\[ R(s)=U(s)\\text{SMA}^n(s)=\\frac{A}{n!}\\frac{n!}{s^{n+1}}\\frac{1}{T^n}\\sum^n_{k=0}(-1)^k\\binom{n}{k}e^{-kTs} \\tag{7} \\] Apply inverse laplace transform on (7), in case of all SMAs have same amplitude, for simplicity. \\[ r(t)=\\mathcal{L^{-1}}\\{R(s)\\}=\\frac{A}{n!}\\frac{1}{T^n}\\sum^n_{k=0}(-1)^k\\binom{n}{k}(t-kT)^nH(t-kT) \\tag{8} \\] Let's investigate first Heaviside section. \\[ r(t)=\\frac{A}{n!}\\frac{1}{T^n}t^n\\ (t \\leq T) \\tag{9} \\] And we can prove important characteristics about derivatives. \\[ \\therefore \\frac{d^k r(t)}{dt^k} = \\frac{A}{(n-k)!T^n}t^{n-k}\\ (\\leq \\frac{A}{T^k}) \\tag{10} \\] (10) implies the derivative of results, is always smaller than initial amplitude / nested SMA's amplitude. If we generalize the results in case of SMAs have different amplitude, and first sections, \\[ \\frac{d^k r(t)}{dt^k} \\leq \\frac{A}{\\prod_{n=1}^{k} T_{n}} \\] Here is an example, step input with 10.0 , applied with 5 filters, SMA amplitude with 2.0s, 2.0s, 1.0s, 0.5s, 0.50 You can see that, (first section, see t < 2.0s ) Velocity <= 10.0 / 2.0 = 5.0 Acceleration <= 10.0 / (2.0*2.0) = 2.5 Jerk <= 10.0 / (2.0*2.0*1.0) = 2.5 snap <= 10.0 / (2.0*2.0*1.0*0.5) = 5.0 Implementation details about SMA \u00b6 The mean over last N data-points calculated as \\[ y[n] = \\frac{1}{N}\\sum_{i=0}^{N-1}x[n-i] \\tag{11} \\] Iterating all over the N data points is computationally expensive. However, averaging all data at each time will provide a numerically stable results in long time calculation. Other way to calculate SMA is (called as recursive/cumulative), \\[ y[n+1] = y[n] + \\frac{1}{N}(x[n+1]-x[n-k+1]) \\] Calculating SMA by cumulative method suffers from numerical error on long time operation. In order to minimize numerical error, i implemented Kahan summation algorithm . averaging angles. \u00b6 What if samples are on the different algebra space? For example, we should use circular mean for angle. \\[ \\bar{\\alpha} = \\text{atan2}(\\frac{1}{n}\\sum^n_{j=1} \\text{sin} (\\alpha_{j}), \\sum^n_{j=1} \\text{cos} (\\alpha_{j})) \\]","title":"Theory"},{"location":"theory/#theory-inside-nested-shaper","text":"","title":"Theory inside nested-shaper"},{"location":"theory/#definitions-of-convolution","text":"\\[ h(t) = \\int_{-\\infty}^{\\infty}f(x)g(t-x)dx=f(t)*g(t) \\tag{continuous domain} \\] \\[ h[n] = (f*g)[n]=\\sum_{i=0}^{K-1}f[k] \\cdot g[n-k] \\tag{discrete domain} \\]","title":"Definitions of Convolution"},{"location":"theory/#the-convolution-theorem","text":"\\[ h = f * g \\iff H[m] = F[m] \\cdot G[m] \\iff H(s)= F(s)G(s) \\]","title":"The Convolution Theorem"},{"location":"theory/#step-and-sma-function-in-frequency-domain","text":"Step function, defined by \\[ u(t)=\\begin{cases} 0 & \\text{if } t < 0 \\\\ A & \\text{if } t \\geq 0 \\\\ \\end{cases} \\to U(s)=\\mathcal{L}\\{u(t)\\}=\\frac{A}{s} \\tag{1} \\] SMA function, defined by \\[ \\text{SMA}_k(t)=\\frac{1}{T_k}(H(t)-H(t-T_k)) \\to \\text{SMA}_k(s) = \\mathcal{L}\\{SMA_k(t)\\} = \\frac{1}{T_k}(\\frac{1-e^{T_ks}}{s}) \\tag{2} \\] Heaviside unit step, defined by \\[ H(t)=\\begin{cases} 1 & \\text{if } t \\geq 0 \\\\ 0 & \\text{if } t < 0 \\\\ \\end{cases} \\]","title":"Step and SMA function in frequency domain"},{"location":"theory/#laplace-transforms-used-in-this-theory","text":"\\[ \\mathcal{L}\\{t^{n}\\}=\\frac{n!}{s^{n+1}} \\tag{3} \\] \\[ \\mathcal{L}\\{H(t-a)\\}=\\frac{e^{-as}}{s}\\ (a \\geq 0) \\tag{4} \\] \\[ \\mathcal{L}\\{f(t-a)H(t-a)\\}=e^{-as}\\mathcal{L}\\{f(t)\\} \\tag{5} \\]","title":"Laplace transforms used in this theory"},{"location":"theory/#step-function-with-nested-sma","text":"Based on the convolution theorem, we apply nested SMAs(total n) on step function. $$ R(s)=U(s)\\text{SMA}_1(s)\\text{SMA}_2(s)\\cdots\\text{SMA}_n(s) $$ \\[ =\\frac{A}{s^{n+1}}\\frac{1}{T_1T_2\\cdots T_n}(1-e^{T_1s})(1-e^{T_2s})\\cdots (1-e^{T_ns})=\\frac{A}{n!}\\frac{n!}{s^{n+1}}\\frac{1}{\\prod^{n}_{k=1}T_{k}}\\prod^{n}_{k=1}(1-e^{T_ks}) \\] \\[ =\\frac{A}{n!}\\frac{n!}{s^{n+1}}\\frac{1}{\\prod^{n}_{k=1}T_{k}}\\sum^{n}_{k=0}(-1)^k\\sum_{\\stackrel{I\\subseteq\\{1,2,\\cdots,n\\}}{|I|=k}}e^{-s\\sum_{i\\in I}T_i} \\tag{6} \\] If SMAs have same amplitude, \\[ R(s)=U(s)\\text{SMA}^n(s)=\\frac{A}{n!}\\frac{n!}{s^{n+1}}\\frac{1}{T^n}\\sum^n_{k=0}(-1)^k\\binom{n}{k}e^{-kTs} \\tag{7} \\] Apply inverse laplace transform on (7), in case of all SMAs have same amplitude, for simplicity. \\[ r(t)=\\mathcal{L^{-1}}\\{R(s)\\}=\\frac{A}{n!}\\frac{1}{T^n}\\sum^n_{k=0}(-1)^k\\binom{n}{k}(t-kT)^nH(t-kT) \\tag{8} \\] Let's investigate first Heaviside section. \\[ r(t)=\\frac{A}{n!}\\frac{1}{T^n}t^n\\ (t \\leq T) \\tag{9} \\] And we can prove important characteristics about derivatives. \\[ \\therefore \\frac{d^k r(t)}{dt^k} = \\frac{A}{(n-k)!T^n}t^{n-k}\\ (\\leq \\frac{A}{T^k}) \\tag{10} \\] (10) implies the derivative of results, is always smaller than initial amplitude / nested SMA's amplitude. If we generalize the results in case of SMAs have different amplitude, and first sections, \\[ \\frac{d^k r(t)}{dt^k} \\leq \\frac{A}{\\prod_{n=1}^{k} T_{n}} \\] Here is an example, step input with 10.0 , applied with 5 filters, SMA amplitude with 2.0s, 2.0s, 1.0s, 0.5s, 0.50 You can see that, (first section, see t < 2.0s ) Velocity <= 10.0 / 2.0 = 5.0 Acceleration <= 10.0 / (2.0*2.0) = 2.5 Jerk <= 10.0 / (2.0*2.0*1.0) = 2.5 snap <= 10.0 / (2.0*2.0*1.0*0.5) = 5.0","title":"Step function with nested SMA."},{"location":"theory/#implementation-details-about-sma","text":"The mean over last N data-points calculated as \\[ y[n] = \\frac{1}{N}\\sum_{i=0}^{N-1}x[n-i] \\tag{11} \\] Iterating all over the N data points is computationally expensive. However, averaging all data at each time will provide a numerically stable results in long time calculation. Other way to calculate SMA is (called as recursive/cumulative), \\[ y[n+1] = y[n] + \\frac{1}{N}(x[n+1]-x[n-k+1]) \\] Calculating SMA by cumulative method suffers from numerical error on long time operation. In order to minimize numerical error, i implemented Kahan summation algorithm .","title":"Implementation details about SMA"},{"location":"theory/#averaging-angles","text":"What if samples are on the different algebra space? For example, we should use circular mean for angle. \\[ \\bar{\\alpha} = \\text{atan2}(\\frac{1}{n}\\sum^n_{j=1} \\text{sin} (\\alpha_{j}), \\sum^n_{j=1} \\text{cos} (\\alpha_{j})) \\]","title":"averaging angles."}]}